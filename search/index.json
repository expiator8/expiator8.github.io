[{"content":"목표 시나리오 FastAPI로 진행\n이미지를 7장을 생성하고 생성 결과를 s3에 업로드하는 api를 작성\n이미지를 생성하기 위해서는 외부 이미지 서버에 요청을 해야함.\n이미지 서버에 이미지 생성 최대 병렬 요청 가능한 클라이언트 수는 5,\ns3에 업로드 최대 병렬 요청 가능한 수는 25로 설정.\n이 작업들을 비동기로 수행해 때문에 실제로 모두 완료되기까지 시간이 오래 걸리지만\n바로 완료가 된 것처럼 메시지를 Response 해야함.\n다시말해 api 서버는 여러가지 10000개의 api 요청을 병렬로 받을 수도 있지만 이미지를 생성하는 특정 api들에 대해서는 최대 5개까지의 요청을 처리하고 s3 업로드는 최대 25개까지의 처리가 되어야한다!\nthread를 사용한 비동기 작업 처리 ThreadPoolExecutor 먼저 여러 스레드를 사용해 비동기 작업을 처리하기 위해\npython concurrent.futures 내장 모듈에서 제공하는 ThreadPoolExecutor를 활용해서\n아래처럼 slow api를 만들고 호출하면 결과는 다음과 같이 나온다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import time from concurrent.futures import ThreadPoolExecutor from fastapi import FastAPI image_server_executor = ThreadPoolExecutor(max_workers=5) s3_upload_executor = ThreadPoolExecutor(max_workers=25) app = FastAPI(debug=True) def generate_images(): \u0026#34;\u0026#34;\u0026#34;Generate images from Image server\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;start generate image\u0026#34;) # 이미지 서버에 이미지 생성 요청. 10초 걸린다고 가정 time.sleep(10) return [ \u0026#34;Image1\u0026#34;, \u0026#34;Image2\u0026#34;, \u0026#34;Image3\u0026#34;, \u0026#34;Image4\u0026#34;, \u0026#34;Image5\u0026#34;, \u0026#34;Image6\u0026#34;, \u0026#34;Image7\u0026#34;, ] def upload_image(image): \u0026#34;\u0026#34;\u0026#34;Upload Image to S3\u0026#34;\u0026#34;\u0026#34; # S3에 업로드 요청. 5초 걸린다고 가정 print(\u0026#34;start image upload\u0026#34;) time.sleep(5) return f\u0026#34;upload complete {image}\u0026#34; @app.get(\u0026#34;/slow\u0026#34;) def slow(): print(\u0026#34;start slow api\u0026#34;) # 이미지 생성 작업: 최대 5개의 작업을 병렬로 실행 images = image_server_executor.submit(generate_images).result() # s3 업로드 작업: 이미지 생성 작업의 결과(7개의 이미지)를 사용해 최대 25개의 작업을 병렬로 실행 uploaded_images = [ s3_upload_executor.submit(upload_image, image) for image in images ] return {\u0026#34;message\u0026#34;: \u0026#34;slow task response\u0026#34;} 1 2 3 4 5 6 7 8 9 import requests def main(): response = requests.get(\u0026#34;http://localhost:5000/slow\u0026#34;) print(response.json()) main() 시간이 걸리는 이유는 submit().result()이다.\ngenerate_images의 결과가 완료될 때까지 기다렸다가 upload_image 작업을 할 수 있기 때문에\nresponse를 받기까지 generate_images의 수행 시간 10초 가량이 걸린다.\n여기서 잠깐! uvicorn의 동작 방식 fastapi에서 사용하는 uvicorn web server는 기본적으로 여러 요청을 비동기 처리할 수가 있다.\n예를들어 시간이 1초 걸리는 api를 simple, 시간이 더 길게 10초 걸리는 api를 slow라고 할때 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @app.get(\u0026#34;/simple\u0026#34;) def simple(): print(\u0026#34;start simple api\u0026#34;) time.sleep(1) print(\u0026#34;finish simple api\u0026#34;) return {\u0026#34;message\u0026#34;: \u0026#34;Simple api response\u0026#34;} @app.get(\u0026#34;/slow\u0026#34;) def slow(): print(\u0026#34;start slow api\u0026#34;) time.sleep(10) print(\u0026#34;finish slow api\u0026#34;) return {\u0026#34;message\u0026#34;: \u0026#34;Slow api response\u0026#34;} simple api, slow api 각각 5개의 병렬 요청을 보내면 uvicorn에서는 다음과 같이 동작한다.\n사용한 python api 호출 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import asyncio import aiohttp import ssl async def fetch(session, url, ssl_context): try: async with session.get(url, ssl=ssl_context) as response: if response.headers[\u0026#34;Content-Type\u0026#34;] == \u0026#34;application/json\u0026#34;: return await response.json() # JSON 응답을 반환받는 상황 가정 else: return await response.text() # JSON이 아닌 응답 처리 except Exception as e: return {\u0026#34;error\u0026#34;: str(e)} # 모든 API 호출을 실행하고 결과를 수집 async def fetch_all(urls): ssl_context = ssl.create_default_context() ssl_context.check_hostname = False ssl_context.verify_mode = ssl.CERT_NONE async with aiohttp.ClientSession() as session: tasks = [fetch(session, url, ssl_context) for url in urls] # 결과를 완료되는대로 즉시 출력 for task in asyncio.as_completed(tasks): result = await task print(result) # 결과를 모두 완료된후 한번에 출력할 경우 # results = await asyncio.gather(*tasks) # return results # 비동기 작업을 시작하는 메인 함수 async def main(): urls = [\u0026#34;http://localhost:5000/slow\u0026#34;] * 5 + [\u0026#34;http://localhost:5000/simple\u0026#34;] * 5 results = await fetch_all(urls) # 비동기 메인 함수 실행 asyncio.run(main()) 반면 예를들어 gunicorn에서 동일한 simple, slow api에 각각 5개의 병렬 요청을 보내면 gunicorn에서는 다음과 같이 동작한다.\n요청을 동기 처리하는 gunicorn에서는 slow api를 처리하는 동안 다른 api 호출이 지연된다.\n즉, slow api를 제외한 모든 api가 아무리 빠르게 처리가 가능하더라도 slow api에 영향을 받아 지연될 수 있다.\n*이정도 요청만으로도 nginx에서 timeout을 조정해주기 전엔 504 Gateway Time-out 에러가 발생했다.\n1 2 3 4 5 6 7 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;title\u0026gt;504 Gateway Time-out\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body bgcolor=\u0026#34;white\u0026#34;\u0026gt; \u0026lt;center\u0026gt;\u0026lt;h1\u0026gt;504 Gateway Time-out\u0026lt;/h1\u0026gt;\u0026lt;/center\u0026gt; \u0026lt;hr\u0026gt;\u0026lt;center\u0026gt;nginx/1.14.0 (Ubuntu)\u0026lt;/center\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 location /slow { proxy_read_timeout 1000s; include proxy_params; ... } gunicorn 실행시 worker와 thread 등의 설정으로 어느정도 지연 해소는 가능하다.\n1 gunicorn --workers 1 --threads 5 예를들어 이 경우에는 slow api가 5개의 thread를 전부 사용한다면 그다음 api 호출부터 지연된다.\nuvicorn이 gunicorn의 worker 프로세스로서 동작하게 할수도 있는데 Kubernetes나 Docker Swarm로 프로세스 관리자 역할을 한다면 uvicorn 단일 프로세스로만 사용하면 좋다고 하는 것 같다.\n예전에 공홈에서도 비슷한 의견의 관련글을 분명 봤었던것 같은데..다시 찾아보려고 하니까 공홈은 아니고 뭔가..이상한? 미러링? 사이트에서 글을 찾았다\n예전에도 여기서 본건가? 무슨 사이트지? 공홈이랑 완전 똑같이 생겼다.\n1 gunicorn main:app --worker-class uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000 이런식으로 하면 fastapi에서 gunicorn을 사용하면서도 비동기로 처리된다. 상황에 맞게 잘 사용하면 될것같다.\n그런데 uvicorn.workers.UvicornWorker를 사용할때 \u0026ndash;threads 옵션을 설정하면 요청을 받았을때 threads 개수만큼 먼저 비동기로 시작하고 다음 작업을 처리할까 싶었는데 기대한대로 동작하진 않았다.\n7개의 요청을 보냈는데 5개를 처리하고 다음 2개를 처리하는게 아니라 들어온 요청을 모두 처리한다.\nCelery with ThreadPoolExecutor 이제 10초 지연이 발생하는 generate_images의 작업도 비동기로 처리하려면!\n사실 upload_image 작업을 generate_images 내부에서 수행하면 간단하게 끝낼수도 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def generate_images(): \u0026#34;\u0026#34;\u0026#34;Generate images from Image server\u0026#34;\u0026#34;\u0026#34; print(\u0026#34;start generate image\u0026#34;) # 이미지 서버에 이미지 생성 요청. 10초 걸린다고 가정 time.sleep(10) images = [ \u0026#34;Image1\u0026#34;, \u0026#34;Image2\u0026#34;, \u0026#34;Image3\u0026#34;, \u0026#34;Image4\u0026#34;, \u0026#34;Image5\u0026#34;, \u0026#34;Image6\u0026#34;, \u0026#34;Image7\u0026#34;, ] # s3 업로드 작업: 이미지 생성 작업의 결과(7개의 이미지)를 사용해 최대 25개의 작업을 병렬로 실행 uploaded_images = [ s3_upload_executor.submit(upload_image, image) for image in images ] return uploaded_images def upload_image(image): \u0026#34;\u0026#34;\u0026#34;Upload Image to S3\u0026#34;\u0026#34;\u0026#34; # S3에 업로드 요청. 5초 걸린다고 가정 print(\u0026#34;start image upload\u0026#34;) time.sleep(5) return f\u0026#34;Upload complete {image}\u0026#34; @app.get(\u0026#34;/slow\u0026#34;) def slow(): print(\u0026#34;start slow api\u0026#34;) # 이미지 생성 작업: 최대 5개의 작업을 병렬로 실행 images = image_server_executor.submit(generate_images) return {\u0026#34;message\u0026#34;: \u0026#34;slow task response\u0026#34;} 하지만 서버의 부담을 줄이기위해 Celery를 활용해 generate_images와 upload_image 작업을 비동기로 처리해봤다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import time import logging from concurrent.futures import ThreadPoolExecutor from celery import Celery from fastapi import FastAPI logging.basicConfig(level=logging.INFO) logger = logging.getLogger(__name__) celery_app = Celery( \u0026#34;test\u0026#34;, broker=\u0026#34;redis://127.0.0.1:6379/0\u0026#34;, backend=\u0026#34;redis://127.0.0.1:6379/0\u0026#34;, ) celery_app.conf.update(broker_connection_retry_on_startup=True) def generate_images(): logger.info(\u0026#34;Task started\u0026#34;) time.sleep(10) logger.info(\u0026#34;Task completed\u0026#34;) return [ \u0026#34;Image1\u0026#34;, \u0026#34;Image2\u0026#34;, \u0026#34;Image3\u0026#34;, \u0026#34;Image4\u0026#34;, \u0026#34;Image5\u0026#34;, \u0026#34;Image6\u0026#34;, \u0026#34;Image7\u0026#34;, ] def upload_image(image): \u0026#34;\u0026#34;\u0026#34;Upload Image to S3\u0026#34;\u0026#34;\u0026#34; # S3에 업로드 요청. 5초 걸린다고 가정 logger.info(\u0026#34;start image upload\u0026#34;) time.sleep(5) return f\u0026#34;upload complete {image}\u0026#34; @celery_app.task def generate_image_task(): # 이미지 생성 작업: 최대 5개의 작업을 병렬로 실행 future = image_server_executor.submit(generate_images) images = future.result() # s3 업로드 작업: 이미지 생성 작업의 결과(7개의 이미지)를 사용해 최대 25개의 작업을 병렬로 실행 uploaded_images = [ s3_upload_executor.submit(upload_image, image) for image in images ] image_server_executor = ThreadPoolExecutor(max_workers=5) s3_upload_executor = ThreadPoolExecutor(max_workers=25) app = FastAPI(debug=True) @app.get(\u0026#34;/slow\u0026#34;) def slow(): print(\u0026#34;start slow api\u0026#34;) generate_image_task.delay() return {\u0026#34;message\u0026#34;: \u0026#34;slow task response\u0026#34;} @app.get(\u0026#34;/simple\u0026#34;) def simple(): print(\u0026#34;start simple api\u0026#34;) time.sleep(1) return {\u0026#34;message\u0026#34;: \u0026#34;Simple api response\u0026#34;} 우선 slow api로 7번의 요청을 보냈을때 모든 요청이 빠르게 response 되고 simple, slow api 모두 각각 7번의 요청을 보냈을때도 response가 지연되지 않는다\n대망의 celery의 동작 로그를 확인해보면\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 [2024-09-11 04:42:39,314: INFO/MainProcess] Connected to redis://127.0.0.1:6379/0 [2024-09-11 04:42:39,318: INFO/MainProcess] mingle: searching for neighbors [2024-09-11 04:42:40,333: INFO/MainProcess] mingle: all alone [2024-09-11 04:42:40,360: INFO/MainProcess] celery@0f07f88585ec ready. [2024-09-11 04:43:45,807: INFO/MainProcess] Task main.generate_image_task[bb43fba7-a525-40c0-b7b2-74d079395e66] received [2024-09-11 04:43:45,816: INFO/MainProcess] Task started [2024-09-11 04:43:45,820: INFO/MainProcess] Task main.generate_image_task[41d7869f-c86e-41ce-b190-0ff16087d856] received [2024-09-11 04:43:45,825: INFO/MainProcess] Task started [2024-09-11 04:43:45,827: INFO/MainProcess] Task main.generate_image_task[68f83b0c-acaa-4697-9cf5-dbdc2dd3c573] received [2024-09-11 04:43:45,834: INFO/MainProcess] Task started [2024-09-11 04:43:45,834: INFO/MainProcess] Task main.generate_image_task[12eab662-0a60-4af4-a84f-de441a2054ac] received [2024-09-11 04:43:45,841: INFO/MainProcess] Task started [2024-09-11 04:43:45,847: INFO/MainProcess] Task main.generate_image_task[1587443b-a880-47d4-9ae6-b9f0e56cb78d] received [2024-09-11 04:43:45,850: INFO/MainProcess] Task started [2024-09-11 04:43:45,853: INFO/MainProcess] Task main.generate_image_task[03f48811-6685-4e8c-98fc-e659b1116060] received [2024-09-11 04:43:45,859: INFO/MainProcess] Task main.generate_image_task[d9ca50d0-899e-4015-a545-6d3be800c957] received [2024-09-11 04:43:55,820: INFO/MainProcess] Task completed [2024-09-11 04:43:55,827: INFO/MainProcess] Task completed [2024-09-11 04:43:55,829: INFO/MainProcess] Task started [2024-09-11 04:43:55,830: INFO/MainProcess] start image upload [2024-09-11 04:43:55,831: INFO/MainProcess] Task started [2024-09-11 04:43:55,832: INFO/MainProcess] start image upload [2024-09-11 04:43:55,832: INFO/MainProcess] start image upload [2024-09-11 04:43:55,834: INFO/MainProcess] start image upload [2024-09-11 04:43:55,835: INFO/MainProcess] start image upload [2024-09-11 04:43:55,846: INFO/MainProcess] Task completed [2024-09-11 04:43:55,859: INFO/MainProcess] Task completed [2024-09-11 04:43:55,873: INFO/MainProcess] start image upload [2024-09-11 04:43:55,846: INFO/MainProcess] start image upload [2024-09-11 04:43:55,880: INFO/MainProcess] start image upload [2024-09-11 04:43:55,883: INFO/MainProcess] Task completed [2024-09-11 04:43:55,891: INFO/MainProcess] start image upload [2024-09-11 04:43:55,909: INFO/MainProcess] start image upload [2024-09-11 04:43:55,910: INFO/MainProcess] start image upload [2024-09-11 04:43:55,921: INFO/MainProcess] start image upload [2024-09-11 04:43:55,994: INFO/MainProcess] start image upload [2024-09-11 04:43:55,995: INFO/MainProcess] start image upload [2024-09-11 04:43:56,196: INFO/MainProcess] start image upload [2024-09-11 04:43:56,198: INFO/MainProcess] start image upload [2024-09-11 04:43:56,200: INFO/MainProcess] start image upload [2024-09-11 04:43:56,201: INFO/MainProcess] start image upload [2024-09-11 04:43:56,202: INFO/MainProcess] start image upload [2024-09-11 04:43:56,203: INFO/MainProcess] start image upload [2024-09-11 04:43:56,206: INFO/MainProcess] start image upload [2024-09-11 04:43:56,211: INFO/MainProcess] start image upload [2024-09-11 04:43:56,215: INFO/MainProcess] start image upload [2024-09-11 04:43:56,218: INFO/MainProcess] start image upload [2024-09-11 04:43:56,221: INFO/MainProcess] start image upload [2024-09-11 04:43:56,654: INFO/MainProcess] Task main.generate_image_task[41d7869f-c86e-41ce-b190-0ff16087d856] succeeded in 10.83154621499125s: None [2024-09-11 04:43:56,655: INFO/MainProcess] Task main.generate_image_task[bb43fba7-a525-40c0-b7b2-74d079395e66] succeeded in 10.841315905970987s: None [2024-09-11 04:43:56,671: INFO/MainProcess] Task main.generate_image_task[1587443b-a880-47d4-9ae6-b9f0e56cb78d] succeeded in 10.822779895039275s: None [2024-09-11 04:43:56,685: INFO/MainProcess] Task main.generate_image_task[68f83b0c-acaa-4697-9cf5-dbdc2dd3c573] succeeded in 10.856467631005216s: None [2024-09-11 04:43:56,686: INFO/MainProcess] Task main.generate_image_task[12eab662-0a60-4af4-a84f-de441a2054ac] succeeded in 10.84823512803996s: None [2024-09-11 04:44:00,868: INFO/MainProcess] start image upload [2024-09-11 04:44:00,915: INFO/MainProcess] start image upload [2024-09-11 04:44:01,036: INFO/MainProcess] start image upload [2024-09-11 04:44:01,142: INFO/MainProcess] start image upload [2024-09-11 04:44:01,189: INFO/MainProcess] start image upload [2024-09-11 04:44:01,215: INFO/MainProcess] start image upload [2024-09-11 04:44:01,227: INFO/MainProcess] start image upload [2024-09-11 04:44:01,228: INFO/MainProcess] start image upload [2024-09-11 04:44:01,243: INFO/MainProcess] start image upload [2024-09-11 04:44:01,251: INFO/MainProcess] start image upload [2024-09-11 04:44:05,841: INFO/MainProcess] Task completed [2024-09-11 04:44:05,875: INFO/MainProcess] Task completed [2024-09-11 04:44:05,899: INFO/MainProcess] start image upload [2024-09-11 04:44:05,900: INFO/MainProcess] start image upload [2024-09-11 04:44:05,909: INFO/MainProcess] start image upload [2024-09-11 04:44:05,910: INFO/MainProcess] start image upload [2024-09-11 04:44:05,910: INFO/MainProcess] start image upload [2024-09-11 04:44:05,914: INFO/MainProcess] start image upload [2024-09-11 04:44:05,917: INFO/MainProcess] start image upload [2024-09-11 04:44:05,921: INFO/MainProcess] start image upload [2024-09-11 04:44:05,928: INFO/MainProcess] start image upload [2024-09-11 04:44:05,929: INFO/MainProcess] start image upload [2024-09-11 04:44:05,965: INFO/MainProcess] start image upload [2024-09-11 04:44:06,053: INFO/MainProcess] start image upload [2024-09-11 04:44:06,054: INFO/MainProcess] start image upload [2024-09-11 04:44:06,086: INFO/MainProcess] start image upload [2024-09-11 04:44:06,414: INFO/MainProcess] Task main.generate_image_task[03f48811-6685-4e8c-98fc-e659b1116060] succeeded in 20.559223674994428s: None [2024-09-11 04:44:06,415: INFO/MainProcess] Task main.generate_image_task[d9ca50d0-899e-4015-a545-6d3be800c957] succeeded in 20.554746486013755s: None 7개의 요청을 모두 receive 하고 처리는 5개씩 하고있다!\nimage upload도 5개의 task를 처리하는 동안 최대 25개의 업로드가 처리되고 있는걸 확인할 수 있다!\n테스트에 사용한 celery 실행 명령에서 핵심은 \u0026ndash;pool threads를 해줘야한다.\n1 celery -A main.celery_app worker -l INFO -f logs/celery.log --pool threads 1 2 3 4 5 -P, --pool \u0026lt;pool\u0026gt; Pool implementation. Options: prefork | eventlet | gevent | solo | processes | threads | custom 사실 처음에 ThreadPoolExecutor가 동작하지 않았는데 celery worker 옵션에 threads가 있는걸 보고 적용했더니 된다! celery worker 옵션 참고\n","date":"2024-09-11T00:00:00Z","permalink":"https://expiator8.github.io/p/celery%EC%99%80-thread%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%B9%84%EB%8F%99%EA%B8%B0%EB%B3%91%EB%A0%AC-%EC%9E%91%EC%97%85feat.-fastapi/","title":"Celery와 Thread를 활용한 비동기\u0026병렬 작업(feat. FastAPI)"},{"content":" 가성비가 좋다! 리뷰에서 가격대비 맛도 괜찮아서 돈까스 생태계 교란종이라는 말도 본 적 있음ㅋㅋ\n","date":"2024-08-27T00:00:00Z","permalink":"https://expiator8.github.io/p/%EC%88%98%EC%98%81-%EB%8F%88%EA%B9%8C%EC%8A%A4%EC%A7%91-%ED%82%A8%EA%B5%90/","title":"수영 돈까스집 킨교"}]